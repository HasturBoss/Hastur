---
layout: post
title: 大数据学习9--hadoop完全分布式配置之集群单点启动
tags: [大数据]
categories: 大数据
---

接下来学习完全分布式配置。

<!-- TOC -->

- [1. 前提准备](#1-前提准备)
- [2. 集群部署规划](#2-集群部署规划)
- [3. 配置集群](#3-配置集群)
  - [3.1. 核心配文件](#31-核心配文件)
  - [3.2. 配置HDFS](#32-配置hdfs)
    - [3.2.1. 配置hadoop-env.sh](#321-配置hadoop-envsh)
    - [3.2.2. 配置hdfs-site.xml](#322-配置hdfs-sitexml)
  - [3.3. 配置yarn](#33-配置yarn)
    - [3.3.1. 配置yarn-env.sh](#331-配置yarn-envsh)
    - [3.3.2. 配置yarn-site.xml](#332-配置yarn-sitexml)
  - [3.4. mapreduce配置](#34-mapreduce配置)
    - [3.4.1. mapred-env.sh](#341-mapred-envsh)
    - [3.4.2. mapred-site.xml](#342-mapred-sitexml)
- [4. 集群分发配置好的文件](#4-集群分发配置好的文件)
- [5. 集群单点启动](#5-集群单点启动)
- [6. 遇到的一个问题](#6-遇到的一个问题)
- [7. 查看结果](#7-查看结果)
- [一个问题](#一个问题)

<!-- /TOC -->

# 1. 前提准备

这里需要准备好3台虚拟机，并且要配置好jdk和hadoop环境。具体操作或者遇到问题，请参考我前面的大数据学习1-8的所有博客。

比如将配置好的虚拟机直接进行克隆，并进行相应的修改就可，参考博客[虚拟机克隆](./2019-12-06-大数据学习3--虚拟机克隆.md)

# 2. 集群部署规划

||hadoop102|hadoop103|hadoop104
|:-:|:-:|:-:|:-:|
HDFS|NameNode </br>DataNode |DataNode|SecondaryNameNode</br>DataNode
YARN|NodeManager|ResourceManager</br>NodeManager |NodeManager

> 这个表格的意思就是：102号虚拟机部署NameNode、DataNode和NodeManager，103号部署DataNode、ResourceManager和NodeManager，104号虚拟机部署SecondaryNameNode、DataNode和NodeManager。

# 3. 配置集群

接下来就是集群的一些配置操作，这里主要关注的是hadoop目录下的`etc/hadoop`目录中的下面几个文件：
* core-site.xml
* hdfs-site.xml
* mapred-site.xml
* yarn-site.xml
* hadoop-env.sh
* yarn-env.sh
* mapred-env.sh

## 3.1. 核心配文件

这里在102号虚拟机上操作。

```
[root@hadoop102 hadoop-2.10.0]# vim etc/hadoop/core-site.xml 
```
```
<configuration>
        <!-- 指定HDFS中namenode的地址-->
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://hadoop102:9000</value>
        </property>

        <!--指定hadoop运行时产生文件的存储目录 -->
        <property>
                <name>hadoop.tmp.dir</name>
                <value>/opt/module/hadoop-2.10.0/data/tmp</value>
        </property>
</configuration>
```
> 根据集群部署规划，namenode部署在102，所需就修改为102。

## 3.2. 配置HDFS

### 3.2.1. 配置hadoop-env.sh

```
[root@hadoop102 hadoop-2.10.0]# vim etc/hadoop/hadoop-env.sh 
```
```
# The java implementation to use.
export JAVA_HOME=/opt/module/jdk1.8.0_161
```

### 3.2.2. 配置hdfs-site.xml

```
[root@hadoop102 hadoop-2.10.0]# vim etc/hadoop/hdfs-site.xml
```
```
<configuration>
        <!--指定HDFS副本数量-->
        <property>
                <name>dfs.replication</name>
                <value>3</value>
        </property>

<!--指定hadoop辅助名称节点主机配置-->
<property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop104:50090</value>
</property>
</configuration>
```

## 3.3. 配置yarn

### 3.3.1. 配置yarn-env.sh

```
[root@hadoop102 hadoop-2.10.0]# vim etc/hadoop/yarn-env.sh
```
```
# some Java parameters
export JAVA_HOME=/opt/module/jdk1.8.0_161
```

### 3.3.2. 配置yarn-site.xml

```
[root@hadoop102 hadoop-2.10.0]# vim etc/hadoop/yarn-site.xml
```

```
<configuration>

<!-- Site specific YARN configuration properties -->

<!-- reducer获取数据的方式-->
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
<!-- 指定YARN的ResourceManager的地址-->
<property>
<name>yarn.resourcemanager.hostname</name>
<value>hadoop103</value>
</property>
</configuration>
```

## 3.4. mapreduce配置

### 3.4.1. mapred-env.sh

```
[root@hadoop102 hadoop-2.10.0]# vim etc/hadoop/mapred-env.sh 
```

```
export JAVA_HOME=/opt/module/jdk1.8.0_161
```

### 3.4.2. mapred-site.xml

```
[root@hadoop102 hadoop-2.10.0]# cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml
```

```
[root@hadoop102 hadoop-2.10.0]# vim etc/hadoop/mapred-site.xml
```

```
<configuration>
<!--指定mr运行在yarn上-->
<property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
</property>
</configuration>
```

# 4. 集群分发配置好的文件

把上面配置好的文件通过上一篇blog讲的[集群分发方法](./2019-12-09-大数据学习8--集群分发方法学习.md)，将这些配置好的全部分发的集群中。

```
[root@hadoop102 hadoop-2.10.0]# xsync /opt/module/hadoop-2.10.0/etc/
```

# 5. 集群单点启动

* 如果集群第一次启动，需要格式化NameNode:

在格式化之前必须先删除/log 和/data目录，然后再格式化NameNode。

```
[root@hadoop102 hadoop-2.7.2]# rm -rf logs/ data/
```

> 需要在三台虚拟机都进行删除。


```
[root@hadoop102 hadoop-2.10.0]# hadoop namenode -format
```

如果在最后面几行中找到这行输出，表示格式化成功！
```
19/12/11 14:23:36 INFO common.Storage: Storage directory /opt/module/hadoop-2.10.0/data/tmp/dfs/name has been successfully formatted.
```


* hadoop102启动namenode

```
[root@hadoop102 hadoop-2.10.0]# hadoop-daemon.sh start namenode
starting namenode, logging to /opt/module/hadoop-2.10.0/logs/hadoop-root-namenode-hadoop102.out
[root@hadoop102 hadoop-2.10.0]# jps
4628 NameNode
4709 Jps
```

* hadoop102/103/104分别启动datanode

102:
```
[root@hadoop102 hadoop-2.10.0]# hadoop-daemon.sh start datanode
starting datanode, logging to /opt/module/hadoop-2.10.0/logs/hadoop-root-datanode-hadoop102.out
[root@hadoop102 hadoop-2.10.0]# jps
4739 DataNode
4628 NameNode
4814 Jps
```

103:
```
[root@hadoop103 hadoop-2.10.0]# hadoop-daemon.sh start datanode
starting datanode, logging to /opt/module/hadoop-2.10.0/logs/hadoop-root-datanode-hadoop103.out
[root@hadoop103 hadoop-2.10.0]# jps
4473 Jps
4429 DataNode
```

104:
```
[root@hadoop104 hadoop-2.10.0]# hadoop-daemon.sh start datanode
starting datanode, logging to /opt/module/hadoop-2.10.0/logs/hadoop-root-datanode-hadoop104.out
[root@hadoop104 hadoop-2.10.0]# jps
4434 DataNode
4487 Jps
```

* 启动secondarynamenode

在104启动secondarynamenode：

```
[root@hadoop104 hadoop-2.10.0]# hadoop-daemon.sh start secondarynamenode
starting secondarynamenode, logging to /opt/module/hadoop-2.10.0/logs/hadoop-root-secondarynamenode-hadoop104.out
```

# 6. 遇到的一个问题

这里自己遇到了一个问题，发现用jps命令查看，竟然datanode没有，按照上面的步骤一步一步的操作，应该是没有问题的，这里需要删除`data/tmp/dfs/data`的data目录数据。

```
[root@hadoop103 hadoop-2.10.0]# rm -rf data/tmp/dfs/data/
```

然后再重新格式化一下，然后启动namenode或者datanode。

> 这里也就是说明了在格式化Namenode之前，一定要先删除data/ 和 logs/ 目录的内容。

# 7. 查看结果

在浏览器中输入：
```
http://hadoop102:50070/
```

选择datanodes标签页，可以看到上面有3个节点，即表示集群配置成功。


![](https://gitee.com/zhangzh_cs/md_image/raw/cd05d241ec514a95a6b582983748d6b3143b103a/2019-12/%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E6%88%90%E5%8A%9F.png)


# 一个问题

在实际中一个集群中有很多节点需要启动，那么是一个一个去启动这些节点吗？这显然是费力不讨好的事情，所以就需要用到ssh免密登录来进行群起集群操作，加下来请看下面一篇博客[ssh免密登录和群起集群](/2019-12-11-大数据学习10--ssh免密登录和群起集群.md)。

