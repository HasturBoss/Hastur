---
layout: post
title: 大数据学习5--hadoop本地运行模式
tags: [大数据]
categories: 大数据
---

经过前面几篇博客的介绍，接下来开始正式进入hadoop的学习。首先是hadoop的单节集群学习。参考文档：https://hadoop.apache.org/docs/r2.10.0/hadoop-project-dist/hadoop-common/SingleCluster.html 。

Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式。接下来3篇博客分别讲述Hadoop的运行模式。首先是本地模式。

<!-- TOC -->

- [1. hadoop命令](#1-hadoop命令)
- [2. 本地模式操作](#2-本地模式操作)
  - [2.1. grep例子](#21-grep例子)
  - [2.2. wordcount例子](#22-wordcount例子)

<!-- /TOC -->



# 1. hadoop命令


输入下面的命令看看是否输出：hadoop脚本的使用文档。
```
[zohar@hadoop100 hadoop-2.7.2]$ bin/hadoop
Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]
  CLASSNAME            run the class named CLASSNAME
 or
  where COMMAND is one of:
  fs                   run a generic filesystem user client
  version              print the version
  jar <jar>            run a jar file
                       note: please use "yarn jar" to launch
                             YARN applications, not this command.
  checknative [-a|-h]  check native hadoop and compression libraries availability
  distcp <srcurl> <desturl> copy file or directories recursively
  archive -archiveName NAME -p <parent path> <src>* <dest> create a hadoop archive
  classpath            prints the class path needed to get the
                       Hadoop jar and the required libraries
  credential           interact with credential providers
  daemonlog            get/set the log level for each daemon
  trace                view and modify Hadoop tracing settings

Most commands print help when invoked w/o parameters.
```
> 可以看到输出了hadoop脚本说明，说明我这里是配置好了。这里需要注意的是，这里需要切换到hadoop的安装目录下。如果没有，请输入：`cd /opt/module/hadoop-2.10.0`。

# 2. 本地模式操作

## 2.1. grep例子

依次输入下面的命令：
```
 $ mkdir input
  $ cp etc/hadoop/*.xml input
  $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output 'dfs[a-z.]+'
  $ cat output/*
```

> 指令的意思：
> bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar    grep     input    output   'dfs[a-z.]+'
>    |        |                               |                                 |         |         |         |
> hadoop命令 运行jar包                   具体运行哪个jar程序                  指定grep例子  输入目录  输出目录  按照正则规则


  输出：
```
1	dfsadmin
```

可以看到运行成功了。

## 2.2. wordcount例子

下面再看一个wordcount例子：看看统计单词的数目。

创建wcinput目录：
```
mkdir wcinput
```

给文件输入内容：
```
vim wc.input
```
然后我这里输入的是：
```
zhangzhihong hadoop helloworld zhangzhihong a this a haha
```
> 这里随便写，这个例子就是统计单词重复出现的次数。

运行命令：
```
[root@hadoop100 hadoop-2.10.0]# bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.0.jar wordcount wc.input wcoutput
```

> 指令运行的意思：
> bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.0.jar       wordcount              wc.input  wcoutput
>    |        |                               |                                        |                     |         |
> hadoop命令  指定运行jar  具体运行哪个jar（example可以包含多个例子，如grep、wordcount） 具体jar的wordcount例子    输入     输出

输出：
```
[root@hadoop100 hadoop-2.10.0]# cat wcoutput/*
a	2
hadoop	1
haha	1
helloworld	1
this	1
zhangzhihong	2
```

> 可以发现，这个统计是可以运行的。

