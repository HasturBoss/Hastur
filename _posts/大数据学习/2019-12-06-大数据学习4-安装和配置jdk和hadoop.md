---
layout: post
title: 大数据学习4--安装和配置jdk和hadoop
tags: [大数据]
categories: 大数据
typora-root-url: ..\..
---

这篇博客就是关于jdk和hadoop的安装，因为这些都是开发大数据必须要做的。

<!-- TOC -->

- [1. 使用sudo命令遇到的问题](#1-使用sudo命令遇到的问题)
- [2. 上传jdk和hadoop到虚拟机](#2-上传jdk和hadoop到虚拟机)
  - [2.1. 安装lrzsz](#21-安装lrzsz)
- [3. 卸载Linux系统原有jdk](#3-卸载linux系统原有jdk)
- [4. jdk和hadoop下载](#4-jdk和hadoop下载)
- [5. jdk和hadoop安装](#5-jdk和hadoop安装)
  - [5.1. 创建module和software 目录](#51-创建module和software-目录)
  - [5.2. 修改目录属性](#52-修改目录属性)
  - [5.3. 上传jdk和hadoop文件到虚拟机](#53-上传jdk和hadoop文件到虚拟机)
  - [5.4. 修改jdk和hadoop属性](#54-修改jdk和hadoop属性)
  - [5.5. 解压jdk和hadoop](#55-解压jdk和hadoop)
- [6. 添加JAVA环境变量](#6-添加java环境变量)
- [7. 添加Hadoop环境变量](#7-添加hadoop环境变量)
- [8. hadoop目录结构](#8-hadoop目录结构)

<!-- /TOC -->

# 1. 使用sudo命令遇到的问题

这里遇到一个问题，情况描述如下：当输入`sudo mkdir /opt/software /opt/module`的时候，系统提示：`zohar 不在 sudoers 文件中。此事将被报告。`。

解决方法：
* 切换到root。`su`命令。
* 输入`vim /etc/sudoers`，参照下面的内容把用户添加进去。

```
root    ALL=(ALL)       ALL
zohar   ALL=(ALL)       NOPASSWD: ALL
```
> 这里的意思就是当使用`sudo`命令的时候，可以不用输入密码。

# 2. 上传jdk和hadoop到虚拟机

上传到虚拟机的方法有很多，比如用vmtools提供的共享，ftp等方法，这里我使用rzsz的zmodem文件传输协议这个方法。

## 2.1. 安装lrzsz

```
sudo yum -y install lrzsz
```

上传文件执行`rz`，下载文件使用`sz`。

安装完成之后，可以直接把想要上传到节点服务器的内容拖到XShell软件界面里面，可以自动完成上传。

# 3. 卸载Linux系统原有jdk

使用`java -verion`查看jdk版本，发现我的系统jdk版本为1.7的，而我上传的为1.8的，为了防止出现版本错误，所以，这里，我先卸载系统原来就有的jdk版本。如果没有则忽略这一步骤。

输入命令：
```
rpm -qa |grep java | xargs sudo rpm -e --nodeps
```
即可。

然后看看再输入`java -version`，就可以发现没有输出内容了。

# 4. jdk和hadoop下载

这里给出jdk和hadoop下载链接，使用百度云进行分享。

|名称|地址|分享码|
|:-:|:-:|:-:|
|jdk|https://pan.baidu.com/s/1Cx-yvKv5GO_n6QTGiTKnDQ|vd59|
|hadoop|https://pan.baidu.com/s/1N_LHyG9o8oDz_DkRHiHGLw|vrcc|

# 5. jdk和hadoop安装

## 5.1. 创建module和software 目录

```
[hadoop100@hadoop100 opt]$ sudo mkdir module
[hadoop100@hadoop100 opt]$ sudo mkdir software
```

> software主要存放的是一些软件包（包括软件压缩包等），module主要是存放的是软件程序（也就是解压的程序或者安装后的程序）。

## 5.2. 修改目录属性

```
[hadoop100@hadoop100 opt]$ sudo chown hadoop100:hadoop100 module/ software/
[hadoop100@hadoop100 opt]$ ll
总用量 12
drwxr-xr-x. 2 hadoop100 hadoop100 4096 6月  13 22:31 module
drwxr-xr-x. 2 hadoop100 hadoop100 4096 6月  13 22:31 software
```

> 这里用户名可能与上面的不一致（如这里是hadoop100，前面是zoahr），这里是后面增补的内容，需要稍微注意一下，自己改成一样的就可以了。

## 5.3. 上传jdk和hadoop文件到虚拟机

如果直接用虚拟机的浏览器进行下载，当下在完成之后，到对应的下载目录找到即可进行下一步操作。

如果是在Windows主机上下载的jdk和hadoop，那么则需要把下载好的jdk和hadoop上传到虚拟机上，下面如何进行上传呢？

在这里提供两种方式：

1. 前面介绍的共享方式，具体设置见[大数据学习2--CentOS配置](/2019-12-05-大数据学习2--CentOS配置.md)，这里不再赘述。找到对应的目录，然后`cp`命名复制过来即可。
2. 利用`rzsz`上传下载命令进行，下面也就是利用这个命名来进行上传和下载操作的。

在本章节的第一部分首先就介绍了rzsz的下载安装，也就是为当前做准备的，具体可以看前面第一部分内容[安装lrzsz](#21-安装lrzsz)

首先，切换到`/opt/software`目录下；
接下来，输入: `sudo rz` 在对应的对话框下选择jdk 或者hadoop文件，即可完成上传。（注意：如果在非root用户下，则需要是用`sudo`，否则将会上传不成功。）

![](/picture/rzsz上传和下载.jpg)

hadoop上传也和上面的操作一样，具体不再赘述。

## 5.4. 修改jdk和hadoop属性

```
[zohar@hadoop100 software]$ sudo chown zohar:zohar hadoop-2.7.2.tar.gz jdk-8u144-linux-x64.tar.gz 
[zohar@hadoop100 software]$ ll
总用量 374196
-rw-r--r--. 1 zohar zohar 197657687 5月  22 2017 hadoop-2.7.2.tar.gz
-rw-r--r--. 1 zohar zohar 185515842 6月  13 23:04 jdk-8u144-linux-x64.tar.gz
```

## 5.5. 解压jdk和hadoop

解压jdk：
```
tar -xvzf jdk-8u161-linux-x64.tar.gz -C /opt/module/
```
解压hadoop：
```
tar -xvzf hadoop-2.10.0.tar.gz -C /opt/module/
```
> 这里在/opt目录下创建了software和module两个目录，software目录就是装软件包的，module就是装软件的。

# 6. 添加JAVA环境变量

打开环境变量编辑的文件：
```
sudo vim /etc/profile
```

在文件末尾添加如下内容：
```
#JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_161
export PATH=$PATH:$JAVA_HOME/bin
```
> export 是为了让JAVA_HOME和PATH变量成为全局变量。

接下来就是让环境变量生效：
```
source /etc/profile
```

测试是否成功：
```
[zohar@hadoop100 module]$ java -version
java version "1.8.0_161"
Java(TM) SE Runtime Environment (build 1.8.0_161-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)
```

# 7. 添加Hadoop环境变量

同添加JAVA环境变量一样，打开`etc/profile`文件，在末尾添加如下内容：
```
#hadoop
export HADOOP_HOME=/opt/module/hadoop-2.10.0
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

让环境变量生效：
```
source /etc/profile
```

查看是否安装成功：
输入:`hadoop version`。
```
[zohar@hadoop100 module]$ hadoop version
Hadoop 2.10.0
Subversion ssh://git.corp.linkedin.com:29418/hadoop/hadoop.git -r e2f1f118e465e787d8567dfa6e2f3b72a0eb9194
Compiled by jhung on 2019-10-22T19:10Z
Compiled with protoc 2.5.0
From source with checksum 7b2d8877c5ce8c9a2cca5c7e81aa4026
This command was run using /opt/module/hadoop-2.10.0/share/hadoop/common/hadoop-common-2.10.0.jar
```

# 8. hadoop目录结构

```
[zohar@hadoop100 hadoop-2.7.2]$ ll
总用量 52
drwxr-xr-x. 2 zohar zohar  4096 5月  22 2017 bin
drwxr-xr-x. 3 zohar zohar  4096 5月  22 2017 etc
drwxr-xr-x. 2 zohar zohar  4096 5月  22 2017 include
drwxr-xr-x. 3 zohar zohar  4096 5月  22 2017 lib
drwxr-xr-x. 2 zohar zohar  4096 5月  22 2017 libexec
-rw-r--r--. 1 zohar zohar 15429 5月  22 2017 LICENSE.txt
-rw-r--r--. 1 zohar zohar   101 5月  22 2017 NOTICE.txt
-rw-r--r--. 1 zohar zohar  1366 5月  22 2017 README.txt
drwxr-xr-x. 2 zohar zohar  4096 5月  22 2017 sbin
drwxr-xr-x. 4 zohar zohar  4096 5月  22 2017 share
```

> bin目录：存放对Hadoop相关服务（HDFS、YARN）进行操作的脚本；
> etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件
> lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能）
> sbin目录：存放启动或者停止Hadoop相关服务脚本
> share目录：存放Hadoop所依赖的jar包、文档和官方案例

